{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aziyu6d2rrIE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcoRsAkbzLZj",
        "outputId": "6de90801-4af6-44bb-a89e-12414c169f02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "4bPgMLsYzVGo",
        "outputId": "debe1df1-fe71-4474-8563-7a8f0c129518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "plane cat   ship  bird \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ImprovedNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImprovedNet, self).__init__()\n",
        "        # First convolutional block\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # 32x32 -> 32x32\n",
        "        self.bn1   = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 32x32 -> 32x32\n",
        "        self.bn2   = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)                           # 32x32 -> 16x16\n",
        "        self.drop1 = nn.Dropout(0.25)\n",
        "\n",
        "        # Second convolutional block\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # 16x16 -> 16x16\n",
        "        self.bn3   = nn.BatchNorm2d(128)\n",
        "        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1) # 16x16 -> 16x16\n",
        "        self.bn4   = nn.BatchNorm2d(128)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)                           # 16x16 -> 8x8\n",
        "        self.drop2 = nn.Dropout(0.25)\n",
        "\n",
        "        # Fully connected block\n",
        "        self.fc1   = nn.Linear(128 * 8 * 8, 512)\n",
        "        self.bn_fc = nn.BatchNorm1d(512)\n",
        "        self.drop_fc = nn.Dropout(0.5)\n",
        "        self.fc2   = nn.Linear(512, 10)  # 10 output classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Block 1\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.drop1(x)\n",
        "\n",
        "        # Block 2\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.bn4(self.conv4(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.drop2(x)\n",
        "\n",
        "        # Flatten and Fully Connected Layers\n",
        "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
        "        x = F.relu(self.bn_fc(self.fc1(x)))\n",
        "        x = self.drop_fc(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the improved network\n",
        "net = ImprovedNet()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    dummy_input_large_batch = torch.randn(2, 3, 32, 32)\n",
        "    output_large_batch = net(dummy_input_large_batch)\n",
        "    print(\"Output shape with batch size 2:\", output_large_batch.shape)\n",
        "\n",
        "    net.eval()\n",
        "    dummy_input_single = torch.randn(1, 3, 32, 32)\n",
        "    output_single = net(dummy_input_single)\n",
        "    print(\"Output shape with batch size 1 in eval mode:\", output_single.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq44c85szfmV",
        "outputId": "a0050fa4-a65d-4da7-8b79-31184ca6c6b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape with batch size 2: torch.Size([2, 10])\n",
            "Output shape with batch size 1 in eval mode: torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(),\n",
        "                       lr=0.001,\n",
        "                       betas=(0.9, 0.999),\n",
        "                       eps=1e-08,\n",
        "                       weight_decay=0,\n",
        "                       amsgrad=False)"
      ],
      "metadata": {
        "id": "Y3bneiqxzk7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(optim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IzeLo5dt4SVp",
        "outputId": "1d82c751-37e8-4892-e18c-b58d7dcb1f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on package torch.optim in torch:\n",
            "\n",
            "NAME\n",
            "    torch.optim - :mod:`torch.optim` is a package implementing various optimization algorithms.\n",
            "\n",
            "DESCRIPTION\n",
            "    Most commonly used methods are already supported, and the interface is general\n",
            "    enough, so that more sophisticated ones can also be easily integrated in the\n",
            "    future.\n",
            "\n",
            "PACKAGE CONTENTS\n",
            "    _adafactor\n",
            "    _functional\n",
            "    _multi_tensor (package)\n",
            "    adadelta\n",
            "    adagrad\n",
            "    adam\n",
            "    adamax\n",
            "    adamw\n",
            "    asgd\n",
            "    lbfgs\n",
            "    lr_scheduler\n",
            "    nadam\n",
            "    optimizer\n",
            "    radam\n",
            "    rmsprop\n",
            "    rprop\n",
            "    sgd\n",
            "    sparse_adam\n",
            "    swa_utils\n",
            "\n",
            "CLASSES\n",
            "    builtins.object\n",
            "        torch.optim.optimizer.Optimizer\n",
            "            Adafactor\n",
            "            torch.optim.adadelta.Adadelta\n",
            "            torch.optim.adagrad.Adagrad\n",
            "            torch.optim.adam.Adam\n",
            "            torch.optim.adamax.Adamax\n",
            "            torch.optim.adamw.AdamW\n",
            "            torch.optim.asgd.ASGD\n",
            "            torch.optim.lbfgs.LBFGS\n",
            "            torch.optim.nadam.NAdam\n",
            "            torch.optim.radam.RAdam\n",
            "            torch.optim.rmsprop.RMSprop\n",
            "            torch.optim.rprop.Rprop\n",
            "            torch.optim.sgd.SGD\n",
            "            torch.optim.sparse_adam.SparseAdam\n",
            "    \n",
            "    class ASGD(torch.optim.optimizer.Optimizer)\n",
            "     |  ASGD(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.01, lambd: float = 0.0001, alpha: float = 0.75, t0: float = 1000000.0, weight_decay: float = 0, foreach: Optional[bool] = None, maximize: bool = False, differentiable: bool = False, capturable: bool = False)\n",
            "     |  \n",
            "     |  Implements Averaged Stochastic Gradient Descent.\n",
            "     |  \n",
            "     |  It has been proposed in `Acceleration of stochastic approximation by\n",
            "     |  averaging`_.\n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): iterable of parameters to optimize or dicts defining\n",
            "     |          parameter groups\n",
            "     |      lr (float, Tensor, optional): learning rate (default: 1e-2)\n",
            "     |      lambd (float, optional): decay term (default: 1e-4)\n",
            "     |      alpha (float, optional): power for eta update (default: 0.75)\n",
            "     |      t0 (float, optional): point at which to start averaging (default: 1e6)\n",
            "     |      weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
            "     |      foreach (bool, optional): whether foreach implementation of optimizer\n",
            "     |          is used. If unspecified by the user (so foreach is None), we will try to use\n",
            "     |          foreach over the for-loop implementation on CUDA, since it is usually\n",
            "     |          significantly more performant. Note that the foreach implementation uses\n",
            "     |          ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n",
            "     |          being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n",
            "     |          parameters through the optimizer at a time or switch this flag to False (default: None)\n",
            "     |      maximize (bool, optional): maximize the objective with respect to the\n",
            "     |          params, instead of minimizing (default: False)\n",
            "     |      differentiable (bool, optional): whether autograd should\n",
            "     |          occur through the optimizer step in training. Otherwise, the step()\n",
            "     |          function runs in a torch.no_grad() context. Setting to True can impair\n",
            "     |          performance, so leave it False if you don't intend to run autograd\n",
            "     |          through this instance (default: False)\n",
            "     |      capturable (bool, optional): whether this instance is safe to\n",
            "     |          capture in a CUDA graph. Passing True can impair ungraphed performance,\n",
            "     |          so if you don't intend to graph capture this instance, leave it False\n",
            "     |          (default: False)\n",
            "     |  \n",
            "     |  .. _Acceleration of stochastic approximation by averaging:\n",
            "     |      https://dl.acm.org/citation.cfm?id=131098\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      ASGD\n",
            "     |      torch.optim.optimizer.Optimizer\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.01, lambd: float = 0.0001, alpha: float = 0.75, t0: float = 1000000.0, weight_decay: float = 0, foreach: Optional[bool] = None, maximize: bool = False, differentiable: bool = False, capturable: bool = False)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  step(self, closure=None)\n",
            "     |      Perform a single optimization step.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable, optional): A closure that reevaluates the model\n",
            "     |              and returns the loss.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "    \n",
            "    class Adadelta(torch.optim.optimizer.Optimizer)\n",
            "     |  Adadelta(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 1.0, rho: float = 0.9, eps: float = 1e-06, weight_decay: float = 0, foreach: Optional[bool] = None, *, capturable: bool = False, maximize: bool = False, differentiable: bool = False)\n",
            "     |  \n",
            "     |  Implements Adadelta algorithm.\n",
            "     |  \n",
            "     |  .. math::\n",
            "     |     \\begin{aligned}\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{input}      : \\gamma \\text{ (lr)}, \\: \\theta_0 \\text{ (params)},\n",
            "     |              \\: f(\\theta) \\text{ (objective)}, \\: \\rho \\text{ (decay)},\n",
            "     |              \\: \\lambda \\text{ (weight decay)}                                                \\\\\n",
            "     |          &\\textbf{initialize} :  v_0  \\leftarrow 0 \\: \\text{ (square avg)},\n",
            "     |              \\: u_0 \\leftarrow 0 \\: \\text{ (accumulate variables)}                     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n",
            "     |          &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n",
            "     |          &\\hspace{5mm}if \\: \\lambda \\neq 0                                                    \\\\\n",
            "     |          &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n",
            "     |          &\\hspace{5mm} v_t      \\leftarrow v_{t-1} \\rho + g^2_t (1 - \\rho)                    \\\\\n",
            "     |          &\\hspace{5mm}\\Delta x_t    \\leftarrow   \\frac{\\sqrt{u_{t-1} +\n",
            "     |              \\epsilon }}{ \\sqrt{v_t + \\epsilon}  }g_t \\hspace{21mm}                           \\\\\n",
            "     |          &\\hspace{5mm} u_t  \\leftarrow   u_{t-1}  \\rho +\n",
            "     |               \\Delta x^2_t  (1 - \\rho)                                                        \\\\\n",
            "     |          &\\hspace{5mm}\\theta_t      \\leftarrow   \\theta_{t-1} - \\gamma  \\Delta x_t            \\\\\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |          &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |     \\end{aligned}\n",
            "     |  \n",
            "     |  For further details regarding the algorithm we refer to `ADADELTA: An Adaptive Learning Rate Method`_.\n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): iterable of parameters to optimize or dicts defining\n",
            "     |          parameter groups\n",
            "     |      rho (float, optional): coefficient used for computing a running average\n",
            "     |          of squared gradients (default: 0.9). A higher value of `rho` will\n",
            "     |          result in a slower average, which can be helpful for preventing\n",
            "     |          oscillations in the learning process.\n",
            "     |      eps (float, optional): term added to the denominator to improve\n",
            "     |          numerical stability (default: 1e-6).\n",
            "     |      lr (float, Tensor, optional): coefficient that scale delta before it is applied\n",
            "     |          to the parameters (default: 1.0)\n",
            "     |      weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
            "     |      foreach (bool, optional): whether foreach implementation of optimizer\n",
            "     |          is used. If unspecified by the user (so foreach is None), we will try to use\n",
            "     |          foreach over the for-loop implementation on CUDA, since it is usually\n",
            "     |          significantly more performant. Note that the foreach implementation uses\n",
            "     |          ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n",
            "     |          being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n",
            "     |          parameters through the optimizer at a time or switch this flag to False (default: None)\n",
            "     |      capturable (bool, optional): whether this instance is safe to\n",
            "     |          capture in a CUDA graph. Passing True can impair ungraphed performance,\n",
            "     |          so if you don't intend to graph capture this instance, leave it False\n",
            "     |          (default: False)\n",
            "     |      maximize (bool, optional): maximize the objective with respect to the\n",
            "     |          params, instead of minimizing (default: False)\n",
            "     |      differentiable (bool, optional): whether autograd should\n",
            "     |          occur through the optimizer step in training. Otherwise, the step()\n",
            "     |          function runs in a torch.no_grad() context. Setting to True can impair\n",
            "     |          performance, so leave it False if you don't intend to run autograd\n",
            "     |          through this instance (default: False)\n",
            "     |  \n",
            "     |  .. _ADADELTA\\: An Adaptive Learning Rate Method:\n",
            "     |      https://arxiv.org/abs/1212.5701\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      Adadelta\n",
            "     |      torch.optim.optimizer.Optimizer\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 1.0, rho: float = 0.9, eps: float = 1e-06, weight_decay: float = 0, foreach: Optional[bool] = None, *, capturable: bool = False, maximize: bool = False, differentiable: bool = False)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  step(self, closure=None)\n",
            "     |      Perform a single optimization step.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable, optional): A closure that reevaluates the model\n",
            "     |              and returns the loss.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "    \n",
            "    class Adafactor(torch.optim.optimizer.Optimizer)\n",
            "     |  Adafactor(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.01, beta2_decay: float = -0.8, eps: Tuple[Optional[float], float] = (None, 0.001), d: float = 1.0, weight_decay: float = 0.0, *, foreach: Optional[bool] = None, maximize: bool = False)\n",
            "     |  \n",
            "     |  Implements Adafactor algorithm.\n",
            "     |  \n",
            "     |  .. math::\n",
            "     |      \\begin{aligned}\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{input}      : \\gamma \\text{(lr)}, \\: \\tau\n",
            "     |              \\text{(}\\beta_2\\text{ decay)}, \\: \\theta_0 \\text{(params)}, \\: f(\\theta) \\text{(objective)},    \\\\\n",
            "     |          &\\hspace{15mm}      \\: \\epsilon_1, \\epsilon_2 \\text{ (epsilons)}, \\: d \\text{(clipping threshold)}, \\\\\n",
            "     |          &\\hspace{15mm}      \\: \\lambda \\text{(weight decay)},\n",
            "     |              \\: \\textit{maximize}                                                             \\\\\n",
            "     |          &\\textbf{initialize} : \\: R_0 \\leftarrow 0 \\text{ (second moment row factor)},       \\\\\n",
            "     |          &\\hspace{23mm} \\: C_0 \\leftarrow 0 \\text{ (second moment col factor)},               \\\\\n",
            "     |          &\\hspace{23mm} \\: \\widehat{V}_0 \\leftarrow 0 \\text{ (second moment for vectors)}     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n",
            "     |  \n",
            "     |          &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}:                                       \\\\\n",
            "     |          &\\hspace{10mm}G_t           \\leftarrow   -\\nabla_{\\theta} f_t (\\theta_{t-1})         \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{else}                                                           \\\\\n",
            "     |          &\\hspace{10mm}G_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})          \\\\\n",
            "     |          &\\hspace{5mm}\\widehat{\\beta}_{2_t} \\leftarrow 1 - t^{\\tau}                           \\\\\n",
            "     |          &\\hspace{5mm}\\rho_t         \\leftarrow min(lr, \\frac{1}{\\sqrt{t}})                   \\\\\n",
            "     |          &\\hspace{5mm}\\alpha_t       \\leftarrow max(\\epsilon_2,\n",
            "     |              \\text{RMS}(\\theta_{t-1}))\\rho_t                                                  \\\\\n",
            "     |          &\\hspace{5mm}\\theta_t       \\leftarrow \\theta_{t-1} - \\gamma \\lambda \\theta_{t-1}    \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{if} \\: \\text{dim}(G_t) > 1:                                     \\\\\n",
            "     |          &\\hspace{10mm}R_t           \\leftarrow \\widehat{\\beta}_{2_t}R_{t-1}+\n",
            "     |              (1-\\widehat{\\beta}_{2_t})(G_t \\odot G_t) \\cdot 1_m                               \\\\\n",
            "     |          &\\hspace{10mm}C_t           \\leftarrow \\widehat{\\beta}_{2_t}C_{t-1}+\n",
            "     |              (1-\\widehat{\\beta}_{2_t}) 1^\\top_n \\cdot (G_t \\odot G_t)                         \\\\\n",
            "     |          &\\hspace{10mm}\\widehat{V}_t \\leftarrow\n",
            "     |              \\frac{R_t \\cdot C_t}{max(1^\\top_n \\cdot R_t, \\epsilon_1)}                        \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{else}                                                           \\\\\n",
            "     |          &\\hspace{10mm}\\widehat{V}_t \\leftarrow \\widehat{\\beta}_{2_t}\\widehat{V}_{t-1}+\n",
            "     |              (1-\\widehat{\\beta}_{2_t}) \\cdot (G_t \\odot G_t)                                  \\\\\n",
            "     |          &\\hspace{5mm}U_t            \\leftarrow\n",
            "     |              \\frac{G_t}{max(\\sqrt{\\widehat{V}_t}, \\epsilon_1)}                                \\\\\n",
            "     |          &\\hspace{5mm}\\widehat{U}_t  \\leftarrow \\frac{U_t}{max(1, \\frac{\\text{RMS}(U_t)}{d})} \\\\\n",
            "     |          &\\hspace{5mm}\\theta_t       \\leftarrow \\theta_{t-1} - \\alpha_t \\widehat{U}_t         \\\\\n",
            "     |  \n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |          &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |      \\end{aligned}\n",
            "     |  \n",
            "     |  For further details regarding the algorithm we refer to `Adafactor: Adaptive Learning Rates with Sublinear Memory Cost`_.\n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): iterable of parameters to optimize or dicts defining\n",
            "     |          parameter groups\n",
            "     |      lr (float, Tensor, optional): unlike other optimizers, Adafactor does not require a\n",
            "     |          learning rate, and Shazeer, Noam, and Mitchell Stern do not use lr at all.\n",
            "     |          Deviating from the paper, this implementation uses lr for applying weight\n",
            "     |          decay and as the maximum value for relative step size rho_t. Note that in\n",
            "     |          the paper, a constant of 0.01 is used as the maximum value for relative\n",
            "     |          step size, and so we set 0.01 as the default value. (default: 1e-2)\n",
            "     |      beta2_decay (float, optional): the decay rate of beta2. beta2 standardly refers\n",
            "     |          to the coefficient used for computing the running average of the gradient\n",
            "     |          squared. (default: -0.8)\n",
            "     |      eps (Tuple[float, float], optional): epsilon1 is the term added to the denominator\n",
            "     |          of the update calculation to improve numerical stability. This use of epsilon1\n",
            "     |          deviates from the algorithm written in the paper! See note below for more details.\n",
            "     |          epsilon2 is the term used to avoid having too small a weight update when applying\n",
            "     |          parameter scaling. (default: (None, 1e-3))\n",
            "     |      d (float, optional): the clipping threshold, used to avoid larger-than-desired\n",
            "     |          updates.\n",
            "     |      weight_decay (float, optional): weight decay coefficient (default: 1e-2)\n",
            "     |      foreach (bool, optional): whether foreach implementation of optimizer is used. Note\n",
            "     |          that the foreach implementation uses ~ sizeof(params) more peak memory than the\n",
            "     |          for-loop version due to the intermediates being a tensorlist vs just one tensor.\n",
            "     |          As Adafactor is commonly used when memory is prohibitive, Adafactor will default\n",
            "     |          to the slower single tensor for-loop implementation unless this flag is explicitly\n",
            "     |          True. This behavior is contrary to other optimizers, which will attempt defaulting\n",
            "     |          to foreach on CUDA for faster runtime. (default: None)\n",
            "     |      maximize (bool, optional): maximize the objective with respect to the\n",
            "     |          params, instead of minimizing (default: False)\n",
            "     |  .. Note::\n",
            "     |      The implementation of Adafactor subtly differs from Shazeer, Noam, and Mitchell Stern\n",
            "     |      and implementations in some other frameworks with its use of learning rate and\n",
            "     |      :math:`\\epsilon_1`.\n",
            "     |  \n",
            "     |      Regarding the learning rate hyperparameter: Shazeer, Noam, and Mitchell Stern do not\n",
            "     |      use lr at all, as the stated algorithm uses :math:`\\rho_t` and update clipping to\n",
            "     |      affect the step size.\n",
            "     |  \n",
            "     |      This implementation allows `lr` to influence the maximum value for :math:`\\rho_t`:\n",
            "     |  \n",
            "     |      .. math::\n",
            "     |          \\begin{aligned}\n",
            "     |              &\\hspace{5mm}\\rho_t \\leftarrow min(lr, \\frac{1}{\\sqrt{t}})\n",
            "     |          \\end{aligned}\n",
            "     |  \n",
            "     |      This differs from Shazeer, Noam, and Mitchell Stern, who use a constant of 0.01 as\n",
            "     |      the maximum value of :math:`\\rho_t`\n",
            "     |  \n",
            "     |      .. math::\n",
            "     |          \\begin{aligned}\n",
            "     |              &\\hspace{5mm}\\rho_t \\leftarrow min(0.01, \\frac{1}{\\sqrt{t}})\n",
            "     |          \\end{aligned}\n",
            "     |  \n",
            "     |      Shazeer, Noam, and Mitchell Stern do not enforce an opinion on how weight decay should\n",
            "     |      be computed, and so we use the learning rate as a coefficient for decoupled weight\n",
            "     |      decay, similar to what is suggested in `Decoupled Weight Decay Regularization`_.\n",
            "     |  \n",
            "     |      Regarding the use of :math:`\\epsilon_1`: The implementation attempts to replicate the\n",
            "     |      presumed intention of Shazeer, Noam, and Mitchell Stern to use :math:`\\epsilon_1` as\n",
            "     |      a stabilizing term when the squared gradient becomes small.\n",
            "     |  \n",
            "     |      This stabilization can be written as\n",
            "     |  \n",
            "     |      .. math::\n",
            "     |          \\begin{aligned}\n",
            "     |              &\\hspace{5mm}R_t \\leftarrow \\widehat{\\beta}_{2_t}R_{t-1}+\n",
            "     |                  (1-\\widehat{\\beta}_{2_t})(G_t \\odot G_t + 1_n \\cdot 1^\\top_m) \\cdot 1_m          \\\\\n",
            "     |              &\\hspace{5mm}C_t \\leftarrow \\widehat{\\beta}_{2_t}C_{t-1}+\n",
            "     |                  (1-\\widehat{\\beta}_{2_t}) 1^\\top_n \\cdot (G_t \\odot G_t + 1_n \\cdot 1^\\top_m)    \\\\\n",
            "     |              &\\hspace{5mm}\\widehat{V}_t \\leftarrow\n",
            "     |                  \\frac{R_t \\cdot C_t}{max(1^\\top_n \\cdot R_t, \\epsilon_1)}                        \\\\\n",
            "     |              &\\hspace{5mm}U_t \\leftarrow \\frac{G_t}{max(\\sqrt{\\widehat{V}_t}, \\epsilon_1)}        \\\\\n",
            "     |          \\end{aligned}\n",
            "     |  \n",
            "     |      where the row and column factors of gradient squared :math:`R_t` and :math:`C_t`\n",
            "     |      are left alone, and we apply :math:`\\epsilon_1` at the final calculation of\n",
            "     |      the variance estimate :math:`\\widehat{V}_t` and for the update :math:`U_t`.\n",
            "     |  \n",
            "     |      This is in contrast to Shazeer, Noam, and Mitchell Stern and other frameworks which\n",
            "     |      apply :math:`\\epsilon_1` to both row and column factors of the squared gradient, but\n",
            "     |      not in the calculations after:\n",
            "     |  \n",
            "     |      .. math::\n",
            "     |          \\begin{aligned}\n",
            "     |              &\\hspace{5mm}R_t \\leftarrow \\widehat{\\beta}_{2_t}R_{t-1}+\n",
            "     |                          (1-\\widehat{\\beta}_{2_t})(G_t \\odot G_t + \\epsilon_1 1_n \\cdot 1^\\top_m) \\cdot 1_m          \\\\\n",
            "     |              &\\hspace{5mm}C_t \\leftarrow \\widehat{\\beta}_{2_t}C_{t-1}+\n",
            "     |                          (1-\\widehat{\\beta}_{2_t}) 1^\\top_n \\cdot (G_t \\odot G_t + \\epsilon_1 1_n \\cdot 1^\\top_m)    \\\\\n",
            "     |              &\\hspace{5mm}\\widehat{V}_t \\leftarrow \\frac{R_t \\cdot C_t}{1^\\top_n \\cdot R_t}                          \\\\\n",
            "     |              &\\hspace{5mm}U_t \\leftarrow \\frac{G_t}{\\sqrt{\\widehat{V}_t}}                                            \\\\\n",
            "     |          \\end{aligned}\n",
            "     |  \n",
            "     |  \n",
            "     |  .. _Adafactor\\: Adaptive Learning Rates with Sublinear Memory Cost:\n",
            "     |      https://arxiv.org/pdf/1804.04235\n",
            "     |  .. _Decoupled Weight Decay Regularization:\n",
            "     |      https://arxiv.org/abs/1711.05101\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      Adafactor\n",
            "     |      torch.optim.optimizer.Optimizer\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.01, beta2_decay: float = -0.8, eps: Tuple[Optional[float], float] = (None, 0.001), d: float = 1.0, weight_decay: float = 0.0, *, foreach: Optional[bool] = None, maximize: bool = False) from torch.optim._adafactor.Adafactor\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __setstate__(self, state) from torch.optim._adafactor.Adafactor\n",
            "     |  \n",
            "     |  step(self, closure=None) from torch.optim._adafactor.Adafactor\n",
            "     |      Perform a single optimization step.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable, optional): A closure that reevaluates the model\n",
            "     |              and returns the loss.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "    \n",
            "    class Adagrad(torch.optim.optimizer.Optimizer)\n",
            "     |  Adagrad(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.01, lr_decay: float = 0, weight_decay: float = 0, initial_accumulator_value: float = 0, eps: float = 1e-10, foreach: Optional[bool] = None, *, maximize: bool = False, differentiable: bool = False, fused: Optional[bool] = None)\n",
            "     |  \n",
            "     |  Implements Adagrad algorithm.\n",
            "     |  \n",
            "     |  .. math::\n",
            "     |     \\begin{aligned}\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{input}      : \\gamma \\text{ (lr)}, \\: \\theta_0 \\text{ (params)}, \\: f(\\theta)\n",
            "     |              \\text{ (objective)}, \\: \\lambda \\text{ (weight decay)},                          \\\\\n",
            "     |          &\\hspace{12mm}    \\tau \\text{ (initial accumulator value)}, \\: \\eta\\text{ (lr decay)}\\\\\n",
            "     |          &\\textbf{initialize} :  state\\_sum_0 \\leftarrow \\tau                          \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n",
            "     |          &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n",
            "     |          &\\hspace{5mm} \\tilde{\\gamma}    \\leftarrow \\gamma / (1 +(t-1) \\eta)                  \\\\\n",
            "     |          &\\hspace{5mm} \\textbf{if} \\: \\lambda \\neq 0                                          \\\\\n",
            "     |          &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda \\theta_{t-1}                             \\\\\n",
            "     |          &\\hspace{5mm}state\\_sum_t  \\leftarrow  state\\_sum_{t-1} + g^2_t                      \\\\\n",
            "     |          &\\hspace{5mm}\\theta_t \\leftarrow\n",
            "     |              \\theta_{t-1}- \\tilde{\\gamma} \\frac{g_t}{\\sqrt{state\\_sum_t}+\\epsilon}            \\\\\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |          &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |     \\end{aligned}\n",
            "     |  \n",
            "     |  For further details regarding the algorithm we refer to `Adaptive Subgradient Methods for Online Learning\n",
            "     |  and Stochastic Optimization`_.\n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): iterable of parameters to optimize or dicts defining\n",
            "     |          parameter groups\n",
            "     |      lr (float, Tensor, optional): learning rate (default: 1e-2)\n",
            "     |      lr_decay (float, optional): learning rate decay (default: 0)\n",
            "     |      weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
            "     |      initial_accumulator_value (float, optional): initial value of the\n",
            "     |          sum of squares of gradients (default: 0)\n",
            "     |      eps (float, optional): term added to the denominator to improve\n",
            "     |          numerical stability (default: 1e-10)\n",
            "     |      foreach (bool, optional): whether foreach implementation of optimizer\n",
            "     |          is used. If unspecified by the user (so foreach is None), we will try to use\n",
            "     |          foreach over the for-loop implementation on CUDA, since it is usually\n",
            "     |          significantly more performant. Note that the foreach implementation uses\n",
            "     |          ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n",
            "     |          being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n",
            "     |          parameters through the optimizer at a time or switch this flag to False (default: None)\n",
            "     |      maximize (bool, optional): maximize the objective with respect to the\n",
            "     |          params, instead of minimizing (default: False)\n",
            "     |      differentiable (bool, optional): whether autograd should\n",
            "     |          occur through the optimizer step in training. Otherwise, the step()\n",
            "     |          function runs in a torch.no_grad() context. Setting to True can impair\n",
            "     |          performance, so leave it False if you don't intend to run autograd\n",
            "     |          through this instance (default: False)\n",
            "     |      fused (bool, optional): whether the fused implementation (CPU only) is used.\n",
            "     |          Currently, `torch.float64`, `torch.float32`, `torch.float16`, and `torch.bfloat16`\n",
            "     |          are supported. (default: None). Please note that the fused implementations does not\n",
            "     |          support sparse or complex gradients.\n",
            "     |  .. _Adaptive Subgradient Methods for Online Learning and Stochastic\n",
            "     |      Optimization: http://jmlr.org/papers/v12/duchi11a.html\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      Adagrad\n",
            "     |      torch.optim.optimizer.Optimizer\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.01, lr_decay: float = 0, weight_decay: float = 0, initial_accumulator_value: float = 0, eps: float = 1e-10, foreach: Optional[bool] = None, *, maximize: bool = False, differentiable: bool = False, fused: Optional[bool] = None)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  share_memory(self)\n",
            "     |  \n",
            "     |  step(self, closure=None)\n",
            "     |      Perform a single optimization step.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable, optional): A closure that reevaluates the model\n",
            "     |              and returns the loss.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "    \n",
            "    class Adam(torch.optim.optimizer.Optimizer)\n",
            "     |  Adam(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.001, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0, amsgrad: bool = False, *, foreach: Optional[bool] = None, maximize: bool = False, capturable: bool = False, differentiable: bool = False, fused: Optional[bool] = None)\n",
            "     |  \n",
            "     |  Implements Adam algorithm.\n",
            "     |  \n",
            "     |  .. math::\n",
            "     |     \\begin{aligned}\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{input}      : \\gamma \\text{ (lr)}, \\beta_1, \\beta_2\n",
            "     |              \\text{ (betas)},\\theta_0 \\text{ (params)},f(\\theta) \\text{ (objective)}          \\\\\n",
            "     |          &\\hspace{13mm}      \\lambda \\text{ (weight decay)},  \\: \\textit{amsgrad},\n",
            "     |              \\:\\textit{maximize}                                                              \\\\\n",
            "     |          &\\textbf{initialize} :  m_0 \\leftarrow 0 \\text{ ( first moment)},\n",
            "     |              v_0\\leftarrow 0 \\text{ (second moment)},\\: \\widehat{v_0}^{max}\\leftarrow 0\\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n",
            "     |  \n",
            "     |          &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}:                                       \\\\\n",
            "     |          &\\hspace{10mm}g_t           \\leftarrow   -\\nabla_{\\theta} f_t (\\theta_{t-1})         \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{else}                                                           \\\\\n",
            "     |          &\\hspace{10mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})          \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{if} \\: \\lambda \\neq 0                                           \\\\\n",
            "     |          &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n",
            "     |          &\\hspace{5mm}m_t           \\leftarrow   \\beta_1 m_{t-1} + (1 - \\beta_1) g_t          \\\\\n",
            "     |          &\\hspace{5mm}v_t           \\leftarrow   \\beta_2 v_{t-1} + (1-\\beta_2) g^2_t          \\\\\n",
            "     |          &\\hspace{5mm}\\widehat{m_t} \\leftarrow   m_t/\\big(1-\\beta_1^t \\big)                   \\\\\n",
            "     |          &\\hspace{5mm}\\widehat{v_t} \\leftarrow   v_t/\\big(1-\\beta_2^t \\big)                   \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{if} \\: amsgrad                                                  \\\\\n",
            "     |          &\\hspace{10mm}\\widehat{v_t}^{max} \\leftarrow \\mathrm{max}(\\widehat{v_t}^{max},\n",
            "     |              \\widehat{v_t})                                                                   \\\\\n",
            "     |          &\\hspace{10mm}\\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\widehat{m_t}/\n",
            "     |              \\big(\\sqrt{\\widehat{v_t}^{max}} + \\epsilon \\big)                                 \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{else}                                                           \\\\\n",
            "     |          &\\hspace{10mm}\\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\widehat{m_t}/\n",
            "     |              \\big(\\sqrt{\\widehat{v_t}} + \\epsilon \\big)                                       \\\\\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |          &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |     \\end{aligned}\n",
            "     |  \n",
            "     |  For further details regarding the algorithm we refer to `Adam: A Method for Stochastic Optimization`_.\n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): iterable of parameters to optimize or dicts defining\n",
            "     |          parameter groups\n",
            "     |      lr (float, Tensor, optional): learning rate (default: 1e-3). A tensor LR\n",
            "     |          is not yet supported for all our implementations. Please use a float\n",
            "     |          LR if you are not also specifying fused=True or capturable=True.\n",
            "     |      betas (Tuple[float, float], optional): coefficients used for computing\n",
            "     |          running averages of gradient and its square (default: (0.9, 0.999))\n",
            "     |      eps (float, optional): term added to the denominator to improve\n",
            "     |          numerical stability (default: 1e-8)\n",
            "     |      weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
            "     |      amsgrad (bool, optional): whether to use the AMSGrad variant of this\n",
            "     |          algorithm from the paper `On the Convergence of Adam and Beyond`_\n",
            "     |          (default: False)\n",
            "     |      foreach (bool, optional): whether foreach implementation of optimizer\n",
            "     |          is used. If unspecified by the user (so foreach is None), we will try to use\n",
            "     |          foreach over the for-loop implementation on CUDA, since it is usually\n",
            "     |          significantly more performant. Note that the foreach implementation uses\n",
            "     |          ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n",
            "     |          being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n",
            "     |          parameters through the optimizer at a time or switch this flag to False (default: None)\n",
            "     |      maximize (bool, optional): maximize the objective with respect to the\n",
            "     |          params, instead of minimizing (default: False)\n",
            "     |      capturable (bool, optional): whether this instance is safe to\n",
            "     |          capture in a CUDA graph. Passing True can impair ungraphed performance,\n",
            "     |          so if you don't intend to graph capture this instance, leave it False\n",
            "     |          (default: False)\n",
            "     |      differentiable (bool, optional): whether autograd should\n",
            "     |          occur through the optimizer step in training. Otherwise, the step()\n",
            "     |          function runs in a torch.no_grad() context. Setting to True can impair\n",
            "     |          performance, so leave it False if you don't intend to run autograd\n",
            "     |          through this instance (default: False)\n",
            "     |      fused (bool, optional): whether the fused implementation is used.\n",
            "     |          Currently, `torch.float64`, `torch.float32`, `torch.float16`, and `torch.bfloat16`\n",
            "     |          are supported. (default: None)\n",
            "     |  \n",
            "     |  .. note:: The foreach and fused implementations are typically faster than the for-loop,\n",
            "     |            single-tensor implementation, with fused being theoretically fastest with both\n",
            "     |            vertical and horizontal fusion. As such, if the user has not specified either\n",
            "     |            flag (i.e., when foreach = fused = None), we will attempt defaulting to the foreach\n",
            "     |            implementation when the tensors are all on CUDA. Why not fused? Since the fused\n",
            "     |            implementation is relatively new, we want to give it sufficient bake-in time.\n",
            "     |            To specify fused, pass True for fused. To force running the for-loop\n",
            "     |            implementation, pass False for either foreach or fused. \n",
            "     |  .. Note::\n",
            "     |      A prototype implementation of Adam and AdamW for MPS supports `torch.float32` and `torch.float16`.\n",
            "     |  .. _Adam\\: A Method for Stochastic Optimization:\n",
            "     |      https://arxiv.org/abs/1412.6980\n",
            "     |  .. _On the Convergence of Adam and Beyond:\n",
            "     |      https://openreview.net/forum?id=ryQu7f-RZ\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      Adam\n",
            "     |      torch.optim.optimizer.Optimizer\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.001, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0, amsgrad: bool = False, *, foreach: Optional[bool] = None, maximize: bool = False, capturable: bool = False, differentiable: bool = False, fused: Optional[bool] = None)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  step(self, closure=None)\n",
            "     |      Perform a single optimization step.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable, optional): A closure that reevaluates the model\n",
            "     |              and returns the loss.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "    \n",
            "    class AdamW(torch.optim.optimizer.Optimizer)\n",
            "     |  AdamW(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.001, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0.01, amsgrad: bool = False, *, maximize: bool = False, foreach: Optional[bool] = None, capturable: bool = False, differentiable: bool = False, fused: Optional[bool] = None)\n",
            "     |  \n",
            "     |  Implements AdamW algorithm.\n",
            "     |  \n",
            "     |  .. math::\n",
            "     |     \\begin{aligned}\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{input}      : \\gamma \\text{(lr)}, \\: \\beta_1, \\beta_2\n",
            "     |              \\text{(betas)}, \\: \\theta_0 \\text{(params)}, \\: f(\\theta) \\text{(objective)},\n",
            "     |              \\: \\epsilon \\text{ (epsilon)}                                                    \\\\\n",
            "     |          &\\hspace{13mm}      \\lambda \\text{(weight decay)},  \\: \\textit{amsgrad},\n",
            "     |              \\: \\textit{maximize}                                                             \\\\\n",
            "     |          &\\textbf{initialize} : m_0 \\leftarrow 0 \\text{ (first moment)}, v_0 \\leftarrow 0\n",
            "     |              \\text{ ( second moment)}, \\: \\widehat{v_0}^{max}\\leftarrow 0              \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n",
            "     |  \n",
            "     |          &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}:                                       \\\\\n",
            "     |          &\\hspace{10mm}g_t           \\leftarrow   -\\nabla_{\\theta} f_t (\\theta_{t-1})          \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{else}                                                           \\\\\n",
            "     |          &\\hspace{10mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n",
            "     |          &\\hspace{5mm} \\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\lambda \\theta_{t-1}         \\\\\n",
            "     |          &\\hspace{5mm}m_t           \\leftarrow   \\beta_1 m_{t-1} + (1 - \\beta_1) g_t          \\\\\n",
            "     |          &\\hspace{5mm}v_t           \\leftarrow   \\beta_2 v_{t-1} + (1-\\beta_2) g^2_t          \\\\\n",
            "     |          &\\hspace{5mm}\\widehat{m_t} \\leftarrow   m_t/\\big(1-\\beta_1^t \\big)                   \\\\\n",
            "     |          &\\hspace{5mm}\\widehat{v_t} \\leftarrow   v_t/\\big(1-\\beta_2^t \\big)                   \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{if} \\: amsgrad                                                  \\\\\n",
            "     |          &\\hspace{10mm}\\widehat{v_t}^{max} \\leftarrow \\mathrm{max}(\\widehat{v_t}^{max},\n",
            "     |              \\widehat{v_t})                                                                   \\\\\n",
            "     |          &\\hspace{10mm}\\theta_t \\leftarrow \\theta_t - \\gamma \\widehat{m_t}/\n",
            "     |              \\big(\\sqrt{\\widehat{v_t}^{max}} + \\epsilon \\big)                                 \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{else}                                                           \\\\\n",
            "     |          &\\hspace{10mm}\\theta_t \\leftarrow \\theta_t - \\gamma \\widehat{m_t}/\n",
            "     |              \\big(\\sqrt{\\widehat{v_t}} + \\epsilon \\big)                                       \\\\\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |          &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |     \\end{aligned}\n",
            "     |  \n",
            "     |  For further details regarding the algorithm we refer to `Decoupled Weight Decay Regularization`_.\n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): iterable of parameters to optimize or dicts defining\n",
            "     |          parameter groups\n",
            "     |      lr (float, Tensor, optional): learning rate (default: 1e-3). A tensor LR\n",
            "     |          is not yet supported for all our implementations. Please use a float\n",
            "     |          LR if you are not also specifying fused=True or capturable=True.\n",
            "     |      betas (Tuple[float, float], optional): coefficients used for computing\n",
            "     |          running averages of gradient and its square (default: (0.9, 0.999))\n",
            "     |      eps (float, optional): term added to the denominator to improve\n",
            "     |          numerical stability (default: 1e-8)\n",
            "     |      weight_decay (float, optional): weight decay coefficient (default: 1e-2)\n",
            "     |      amsgrad (bool, optional): whether to use the AMSGrad variant of this\n",
            "     |          algorithm from the paper `On the Convergence of Adam and Beyond`_\n",
            "     |          (default: False)\n",
            "     |      maximize (bool, optional): maximize the objective with respect to the\n",
            "     |          params, instead of minimizing (default: False)\n",
            "     |      foreach (bool, optional): whether foreach implementation of optimizer\n",
            "     |          is used. If unspecified by the user (so foreach is None), we will try to use\n",
            "     |          foreach over the for-loop implementation on CUDA, since it is usually\n",
            "     |          significantly more performant. Note that the foreach implementation uses\n",
            "     |          ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n",
            "     |          being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n",
            "     |          parameters through the optimizer at a time or switch this flag to False (default: None)\n",
            "     |      capturable (bool, optional): whether this instance is safe to\n",
            "     |          capture in a CUDA graph. Passing True can impair ungraphed performance,\n",
            "     |          so if you don't intend to graph capture this instance, leave it False\n",
            "     |          (default: False)\n",
            "     |      differentiable (bool, optional): whether autograd should\n",
            "     |          occur through the optimizer step in training. Otherwise, the step()\n",
            "     |          function runs in a torch.no_grad() context. Setting to True can impair\n",
            "     |          performance, so leave it False if you don't intend to run autograd\n",
            "     |          through this instance (default: False)\n",
            "     |      fused (bool, optional): whether the fused implementation is used.\n",
            "     |          Currently, `torch.float64`, `torch.float32`, `torch.float16`, and `torch.bfloat16`\n",
            "     |          are supported. (default: None)\n",
            "     |  \n",
            "     |  .. note:: The foreach and fused implementations are typically faster than the for-loop,\n",
            "     |            single-tensor implementation, with fused being theoretically fastest with both\n",
            "     |            vertical and horizontal fusion. As such, if the user has not specified either\n",
            "     |            flag (i.e., when foreach = fused = None), we will attempt defaulting to the foreach\n",
            "     |            implementation when the tensors are all on CUDA. Why not fused? Since the fused\n",
            "     |            implementation is relatively new, we want to give it sufficient bake-in time.\n",
            "     |            To specify fused, pass True for fused. To force running the for-loop\n",
            "     |            implementation, pass False for either foreach or fused. \n",
            "     |  .. Note::\n",
            "     |      A prototype implementation of Adam and AdamW for MPS supports `torch.float32` and `torch.float16`.\n",
            "     |  .. _Decoupled Weight Decay Regularization:\n",
            "     |      https://arxiv.org/abs/1711.05101\n",
            "     |  .. _On the Convergence of Adam and Beyond:\n",
            "     |      https://openreview.net/forum?id=ryQu7f-RZ\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      AdamW\n",
            "     |      torch.optim.optimizer.Optimizer\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.001, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0.01, amsgrad: bool = False, *, maximize: bool = False, foreach: Optional[bool] = None, capturable: bool = False, differentiable: bool = False, fused: Optional[bool] = None)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  step(self, closure=None)\n",
            "     |      Perform a single optimization step.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable, optional): A closure that reevaluates the model\n",
            "     |              and returns the loss.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "    \n",
            "    class Adamax(torch.optim.optimizer.Optimizer)\n",
            "     |  Adamax(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.002, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0, foreach: Optional[bool] = None, *, maximize: bool = False, differentiable: bool = False, capturable: bool = False)\n",
            "     |  \n",
            "     |  Implements Adamax algorithm (a variant of Adam based on infinity norm).\n",
            "     |  \n",
            "     |  .. math::\n",
            "     |     \\begin{aligned}\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{input}      : \\gamma \\text{ (lr)}, \\beta_1, \\beta_2\n",
            "     |              \\text{ (betas)},\\theta_0 \\text{ (params)},f(\\theta) \\text{ (objective)},\n",
            "     |              \\: \\lambda \\text{ (weight decay)},                                                \\\\\n",
            "     |          &\\hspace{13mm}    \\epsilon \\text{ (epsilon)}                                          \\\\\n",
            "     |          &\\textbf{initialize} :  m_0 \\leftarrow 0 \\text{ ( first moment)},\n",
            "     |              u_0 \\leftarrow 0 \\text{ ( infinity norm)}                                 \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n",
            "     |          &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n",
            "     |          &\\hspace{5mm}if \\: \\lambda \\neq 0                                                    \\\\\n",
            "     |          &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n",
            "     |          &\\hspace{5mm}m_t      \\leftarrow   \\beta_1 m_{t-1} + (1 - \\beta_1) g_t               \\\\\n",
            "     |          &\\hspace{5mm}u_t      \\leftarrow   \\mathrm{max}(\\beta_2 u_{t-1}, |g_{t}|+\\epsilon)   \\\\\n",
            "     |          &\\hspace{5mm}\\theta_t \\leftarrow \\theta_{t-1} - \\frac{\\gamma m_t}{(1-\\beta^t_1) u_t} \\\\\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |          &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |     \\end{aligned}\n",
            "     |  \n",
            "     |  For further details regarding the algorithm we refer to `Adam: A Method for Stochastic Optimization`_.\n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): iterable of parameters to optimize or dicts defining\n",
            "     |          parameter groups\n",
            "     |      lr (float, Tensor, optional): learning rate (default: 2e-3)\n",
            "     |      betas (Tuple[float, float], optional): coefficients used for computing\n",
            "     |          running averages of gradient and its square\n",
            "     |      eps (float, optional): term added to the denominator to improve\n",
            "     |          numerical stability (default: 1e-8)\n",
            "     |      weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
            "     |      foreach (bool, optional): whether foreach implementation of optimizer\n",
            "     |          is used. If unspecified by the user (so foreach is None), we will try to use\n",
            "     |          foreach over the for-loop implementation on CUDA, since it is usually\n",
            "     |          significantly more performant. Note that the foreach implementation uses\n",
            "     |          ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n",
            "     |          being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n",
            "     |          parameters through the optimizer at a time or switch this flag to False (default: None)\n",
            "     |      maximize (bool, optional): maximize the objective with respect to the\n",
            "     |          params, instead of minimizing (default: False)\n",
            "     |      differentiable (bool, optional): whether autograd should\n",
            "     |          occur through the optimizer step in training. Otherwise, the step()\n",
            "     |          function runs in a torch.no_grad() context. Setting to True can impair\n",
            "     |          performance, so leave it False if you don't intend to run autograd\n",
            "     |          through this instance (default: False)\n",
            "     |      capturable (bool, optional): whether this instance is safe to\n",
            "     |          capture in a CUDA graph. Passing True can impair ungraphed performance,\n",
            "     |          so if you don't intend to graph capture this instance, leave it False\n",
            "     |          (default: False)\n",
            "     |  \n",
            "     |  .. _Adam\\: A Method for Stochastic Optimization:\n",
            "     |      https://arxiv.org/abs/1412.6980\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      Adamax\n",
            "     |      torch.optim.optimizer.Optimizer\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.002, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0, foreach: Optional[bool] = None, *, maximize: bool = False, differentiable: bool = False, capturable: bool = False)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  step(self, closure=None)\n",
            "     |      Performs a single optimization step.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable, optional): A closure that reevaluates the model\n",
            "     |              and returns the loss.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "    \n",
            "    class LBFGS(torch.optim.optimizer.Optimizer)\n",
            "     |  LBFGS(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 1, max_iter: int = 20, max_eval: Optional[int] = None, tolerance_grad: float = 1e-07, tolerance_change: float = 1e-09, history_size: int = 100, line_search_fn: Optional[str] = None)\n",
            "     |  \n",
            "     |  Implements L-BFGS algorithm.\n",
            "     |  \n",
            "     |  Heavily inspired by `minFunc\n",
            "     |  <https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html>`_.\n",
            "     |  \n",
            "     |  .. warning::\n",
            "     |      This optimizer doesn't support per-parameter options and parameter\n",
            "     |      groups (there can be only one).\n",
            "     |  \n",
            "     |  .. warning::\n",
            "     |      Right now all parameters have to be on a single device. This will be\n",
            "     |      improved in the future.\n",
            "     |  \n",
            "     |  .. note::\n",
            "     |      This is a very memory intensive optimizer (it requires additional\n",
            "     |      ``param_bytes * (history_size + 1)`` bytes). If it doesn't fit in memory\n",
            "     |      try reducing the history size, or use a different algorithm.\n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): iterable of parameters to optimize. Parameters must be real.\n",
            "     |      lr (float): learning rate (default: 1)\n",
            "     |      max_iter (int): maximal number of iterations per optimization step\n",
            "     |          (default: 20)\n",
            "     |      max_eval (int): maximal number of function evaluations per optimization\n",
            "     |          step (default: max_iter * 1.25).\n",
            "     |      tolerance_grad (float): termination tolerance on first order optimality\n",
            "     |          (default: 1e-7).\n",
            "     |      tolerance_change (float): termination tolerance on function\n",
            "     |          value/parameter changes (default: 1e-9).\n",
            "     |      history_size (int): update history size (default: 100).\n",
            "     |      line_search_fn (str): either 'strong_wolfe' or None (default: None).\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      LBFGS\n",
            "     |      torch.optim.optimizer.Optimizer\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 1, max_iter: int = 20, max_eval: Optional[int] = None, tolerance_grad: float = 1e-07, tolerance_change: float = 1e-09, history_size: int = 100, line_search_fn: Optional[str] = None)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  step(self, closure)\n",
            "     |      Perform a single optimization step.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable): A closure that reevaluates the model\n",
            "     |              and returns the loss.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setstate__(self, state: Dict[str, Any]) -> None\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "    \n",
            "    class NAdam(torch.optim.optimizer.Optimizer)\n",
            "     |  NAdam(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.002, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0, momentum_decay: float = 0.004, decoupled_weight_decay: bool = False, *, foreach: Optional[bool] = None, maximize: bool = False, capturable: bool = False, differentiable: bool = False)\n",
            "     |  \n",
            "     |  Implements NAdam algorithm.\n",
            "     |  \n",
            "     |  .. math::\n",
            "     |     \\begin{aligned}\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{input}      : \\gamma_t \\text{ (lr)}, \\: \\beta_1,\\beta_2 \\text{ (betas)},\n",
            "     |              \\: \\theta_0 \\text{ (params)}, \\: f(\\theta) \\text{ (objective)}                   \\\\\n",
            "     |          &\\hspace{13mm} \\: \\lambda \\text{ (weight decay)}, \\:\\psi \\text{ (momentum decay)}    \\\\\n",
            "     |          &\\hspace{13mm} \\: \\textit{decoupled\\_weight\\_decay}, \\:\\textit{maximize}             \\\\\n",
            "     |          &\\textbf{initialize} :  m_0 \\leftarrow 0 \\text{ ( first moment)},\n",
            "     |              v_0 \\leftarrow 0 \\text{ ( second moment)}                                 \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}:                                       \\\\\n",
            "     |          &\\hspace{10mm}g_t           \\leftarrow   -\\nabla_{\\theta} f_t (\\theta_{t-1})         \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{else}                                                           \\\\\n",
            "     |          &\\hspace{10mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})          \\\\\n",
            "     |          &\\hspace{5mm} \\theta_t \\leftarrow \\theta_{t-1}                                       \\\\\n",
            "     |          &\\hspace{5mm} \\textbf{if} \\: \\lambda \\neq 0                                          \\\\\n",
            "     |          &\\hspace{10mm}\\textbf{if} \\: \\textit{decoupled\\_weight\\_decay}                       \\\\\n",
            "     |          &\\hspace{15mm} \\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\lambda \\theta_{t-1}                    \\\\\n",
            "     |          &\\hspace{10mm}\\textbf{else}                                                          \\\\\n",
            "     |          &\\hspace{15mm} g_t \\leftarrow g_t + \\lambda \\theta_{t-1}                             \\\\\n",
            "     |          &\\hspace{5mm} \\mu_t \\leftarrow \\beta_1 \\big(1 - \\frac{1}{2}  0.96^{t \\psi} \\big)     \\\\\n",
            "     |          &\\hspace{5mm} \\mu_{t+1} \\leftarrow \\beta_1 \\big(1 - \\frac{1}{2} 0.96^{(t+1)\\psi}\\big)\\\\\n",
            "     |          &\\hspace{5mm}m_t           \\leftarrow   \\beta_1 m_{t-1} + (1 - \\beta_1) g_t          \\\\\n",
            "     |          &\\hspace{5mm}v_t           \\leftarrow   \\beta_2 v_{t-1} + (1-\\beta_2) g^2_t          \\\\\n",
            "     |          &\\hspace{5mm}\\widehat{m_t} \\leftarrow \\mu_{t+1} m_t/(1-\\prod_{i=1}^{t+1}\\mu_i)\\\\[-1.ex]\n",
            "     |          & \\hspace{11mm} + (1-\\mu_t) g_t /(1-\\prod_{i=1}^{t} \\mu_{i})                         \\\\\n",
            "     |          &\\hspace{5mm}\\widehat{v_t} \\leftarrow   v_t/\\big(1-\\beta_2^t \\big)                   \\\\\n",
            "     |          &\\hspace{5mm}\\theta_t \\leftarrow \\theta_t - \\gamma \\widehat{m_t}/\n",
            "     |              \\big(\\sqrt{\\widehat{v_t}} + \\epsilon \\big)                                       \\\\\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |          &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |     \\end{aligned}\n",
            "     |  \n",
            "     |  For further details regarding the algorithm we refer to `Incorporating Nesterov Momentum into Adam`_.\n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): iterable of parameters to optimize or dicts defining\n",
            "     |          parameter groups\n",
            "     |      lr (float, Tensor, optional): learning rate (default: 2e-3)\n",
            "     |      betas (Tuple[float, float], optional): coefficients used for computing\n",
            "     |          running averages of gradient and its square (default: (0.9, 0.999))\n",
            "     |      eps (float, optional): term added to the denominator to improve\n",
            "     |          numerical stability (default: 1e-8)\n",
            "     |      weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
            "     |      momentum_decay (float, optional): momentum momentum_decay (default: 4e-3)\n",
            "     |      decoupled_weight_decay (bool, optional): whether to use decoupled weight\n",
            "     |          decay as in AdamW to obtain NAdamW (default: False)\n",
            "     |      foreach (bool, optional): whether foreach implementation of optimizer\n",
            "     |          is used. If unspecified by the user (so foreach is None), we will try to use\n",
            "     |          foreach over the for-loop implementation on CUDA, since it is usually\n",
            "     |          significantly more performant. Note that the foreach implementation uses\n",
            "     |          ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n",
            "     |          being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n",
            "     |          parameters through the optimizer at a time or switch this flag to False (default: None)\n",
            "     |      maximize (bool, optional): maximize the objective with respect to the\n",
            "     |          params, instead of minimizing (default: False)\n",
            "     |      capturable (bool, optional): whether this instance is safe to\n",
            "     |          capture in a CUDA graph. Passing True can impair ungraphed performance,\n",
            "     |          so if you don't intend to graph capture this instance, leave it False\n",
            "     |          (default: False)\n",
            "     |      differentiable (bool, optional): whether autograd should\n",
            "     |          occur through the optimizer step in training. Otherwise, the step()\n",
            "     |          function runs in a torch.no_grad() context. Setting to True can impair\n",
            "     |          performance, so leave it False if you don't intend to run autograd\n",
            "     |          through this instance (default: False)\n",
            "     |  \n",
            "     |  .. _Incorporating Nesterov Momentum into Adam:\n",
            "     |      https://openreview.net/forum?id=OM0jvwB8jIp57ZJjtNEZ\n",
            "     |  .. _Decoupled Weight Decay Regularization:\n",
            "     |      https://arxiv.org/abs/1711.05101\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      NAdam\n",
            "     |      torch.optim.optimizer.Optimizer\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.002, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0, momentum_decay: float = 0.004, decoupled_weight_decay: bool = False, *, foreach: Optional[bool] = None, maximize: bool = False, capturable: bool = False, differentiable: bool = False)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  step(self, closure=None)\n",
            "     |      Perform a single optimization step.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable, optional): A closure that reevaluates the model\n",
            "     |              and returns the loss.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "    \n",
            "    class Optimizer(builtins.object)\n",
            "     |  Optimizer(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], defaults: Dict[str, Any]) -> None\n",
            "     |  \n",
            "     |  Base class for all optimizers.\n",
            "     |  \n",
            "     |  .. warning::\n",
            "     |      Parameters need to be specified as collections that have a deterministic\n",
            "     |      ordering that is consistent between runs. Examples of objects that don't\n",
            "     |      satisfy those properties are sets and iterators over values of dictionaries.\n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): an iterable of :class:`torch.Tensor` s or\n",
            "     |          :class:`dict` s. Specifies what Tensors should be optimized.\n",
            "     |      defaults: (dict): a dict containing default values of optimization\n",
            "     |          options (used when a parameter group doesn't specify them).\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], defaults: Dict[str, Any]) -> None\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setstate__(self, state: Dict[str, Any]) -> None\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  step(self, closure: Optional[Callable[[], float]] = None) -> Optional[float]\n",
            "     |      Perform a single optimization step to update parameter.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable): A closure that reevaluates the model and\n",
            "     |              returns the loss. Optional for most optimizers.\n",
            "     |      \n",
            "     |      .. note::\n",
            "     |          Unless otherwise specified, this function should not modify the\n",
            "     |          ``.grad`` field of the parameters.\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods defined here:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors defined here:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "     |  \n",
            "     |  __annotations__ = {'OptimizerPostHook': typing.TypeAlias, 'OptimizerPr...\n",
            "    \n",
            "    class RAdam(torch.optim.optimizer.Optimizer)\n",
            "     |  RAdam(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.001, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0, decoupled_weight_decay: bool = False, *, foreach: Optional[bool] = None, maximize: bool = False, capturable: bool = False, differentiable: bool = False)\n",
            "     |  \n",
            "     |  Implements RAdam algorithm.\n",
            "     |  \n",
            "     |  .. math::\n",
            "     |     \\begin{aligned}\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{input}      : \\gamma \\text{ (lr)}, \\: \\beta_1, \\beta_2\n",
            "     |              \\text{ (betas)}, \\: \\theta_0 \\text{ (params)}, \\:f(\\theta) \\text{ (objective)}, \\:\n",
            "     |              \\lambda \\text{ (weightdecay)}, \\:\\textit{maximize}                               \\\\\n",
            "     |          &\\hspace{13mm} \\epsilon \\text{ (epsilon)}, \\textit{decoupled\\_weight\\_decay}         \\\\\n",
            "     |          &\\textbf{initialize} :  m_0 \\leftarrow 0 \\text{ ( first moment)},\n",
            "     |              v_0 \\leftarrow 0 \\text{ ( second moment)},                                       \\\\\n",
            "     |          &\\hspace{18mm} \\rho_{\\infty} \\leftarrow 2/(1-\\beta_2) -1                      \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}  \\\\\n",
            "     |          &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n",
            "     |          &\\hspace{6mm}\\textbf{if} \\: \\textit{maximize}:                                       \\\\\n",
            "     |          &\\hspace{12mm}g_t           \\leftarrow   -\\nabla_{\\theta} f_t (\\theta_{t-1})         \\\\\n",
            "     |          &\\hspace{6mm}\\textbf{else}                                                           \\\\\n",
            "     |          &\\hspace{12mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})          \\\\\n",
            "     |          &\\hspace{6mm} \\theta_t \\leftarrow \\theta_{t-1}                                       \\\\\n",
            "     |          &\\hspace{6mm} \\textbf{if} \\: \\lambda \\neq 0                                          \\\\\n",
            "     |          &\\hspace{12mm}\\textbf{if} \\: \\textit{decoupled\\_weight\\_decay}                       \\\\\n",
            "     |          &\\hspace{18mm} \\theta_t \\leftarrow \\theta_{t} - \\gamma \\lambda \\theta_{t}            \\\\\n",
            "     |          &\\hspace{12mm}\\textbf{else}                                                          \\\\\n",
            "     |          &\\hspace{18mm} g_t \\leftarrow g_t + \\lambda \\theta_{t}                               \\\\\n",
            "     |          &\\hspace{6mm}m_t           \\leftarrow   \\beta_1 m_{t-1} + (1 - \\beta_1) g_t          \\\\\n",
            "     |          &\\hspace{6mm}v_t           \\leftarrow   \\beta_2 v_{t-1} + (1-\\beta_2) g^2_t          \\\\\n",
            "     |          &\\hspace{6mm}\\widehat{m_t} \\leftarrow   m_t/\\big(1-\\beta_1^t \\big)                   \\\\\n",
            "     |          &\\hspace{6mm}\\rho_t \\leftarrow \\rho_{\\infty} -\n",
            "     |              2 t \\beta^t_2 /\\big(1-\\beta_2^t \\big)                                    \\\\[0.1.ex]\n",
            "     |          &\\hspace{6mm}\\textbf{if} \\: \\rho_t > 5                                               \\\\\n",
            "     |          &\\hspace{12mm} l_t \\leftarrow \\frac{\\sqrt{ (1-\\beta^t_2) }}{ \\sqrt{v_t} +\\epsilon  } \\\\\n",
            "     |          &\\hspace{12mm} r_t \\leftarrow\n",
            "     |    \\sqrt{\\frac{(\\rho_t-4)(\\rho_t-2)\\rho_{\\infty}}{(\\rho_{\\infty}-4)(\\rho_{\\infty}-2) \\rho_t}} \\\\\n",
            "     |          &\\hspace{12mm}\\theta_t \\leftarrow \\theta_t - \\gamma \\widehat{m_t} r_t l_t        \\\\\n",
            "     |          &\\hspace{6mm}\\textbf{else}                                                           \\\\\n",
            "     |          &\\hspace{12mm}\\theta_t \\leftarrow \\theta_t - \\gamma \\widehat{m_t}                \\\\\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |          &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |     \\end{aligned}\n",
            "     |  \n",
            "     |  For further details regarding the algorithm we refer to `On the variance of the adaptive learning rate and beyond`_.\n",
            "     |  \n",
            "     |  This implementation provides an option to use either the original weight_decay implementation as in Adam\n",
            "     |  (where the weight_decay is applied to the gradient) or the one from AdamW (where weight_decay is applied\n",
            "     |  to the weight) through the decoupled_weight_decay option. When decoupled_weight_decay is set to False\n",
            "     |  (default), it uses the original Adam style weight decay, otherwise, it uses the AdamW style which\n",
            "     |  corresponds more closely to the `author's implementation`_ in the RAdam paper. Further information\n",
            "     |  about decoupled weight decay can be found in `Decoupled Weight Decay Regularization`_.\n",
            "     |  \n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): iterable of parameters to optimize or dicts defining\n",
            "     |          parameter groups\n",
            "     |      lr (float, Tensor, optional): learning rate (default: 1e-3)\n",
            "     |      betas (Tuple[float, float], optional): coefficients used for computing\n",
            "     |          running averages of gradient and its square (default: (0.9, 0.999))\n",
            "     |      eps (float, optional): term added to the denominator to improve\n",
            "     |          numerical stability (default: 1e-8)\n",
            "     |      weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
            "     |      decoupled_weight_decay (bool, optional): whether to use decoupled weight\n",
            "     |          decay as in AdamW to obtain RAdamW (default: False)\n",
            "     |      foreach (bool, optional): whether foreach implementation of optimizer\n",
            "     |          is used. If unspecified by the user (so foreach is None), we will try to use\n",
            "     |          foreach over the for-loop implementation on CUDA, since it is usually\n",
            "     |          significantly more performant. Note that the foreach implementation uses\n",
            "     |          ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n",
            "     |          being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n",
            "     |          parameters through the optimizer at a time or switch this flag to False (default: None)\n",
            "     |      maximize (bool, optional): maximize the objective with respect to the\n",
            "     |          params, instead of minimizing (default: False)\n",
            "     |      differentiable (bool, optional): whether autograd should\n",
            "     |          occur through the optimizer step in training. Otherwise, the step()\n",
            "     |          function runs in a torch.no_grad() context. Setting to True can impair\n",
            "     |          performance, so leave it False if you don't intend to run autograd\n",
            "     |          through this instance (default: False)\n",
            "     |      capturable (bool, optional): whether this instance is safe to\n",
            "     |          capture in a CUDA graph. Passing True can impair ungraphed performance,\n",
            "     |          so if you don't intend to graph capture this instance, leave it False\n",
            "     |          (default: False)\n",
            "     |  \n",
            "     |  .. _On the variance of the adaptive learning rate and beyond:\n",
            "     |      https://arxiv.org/abs/1908.03265\n",
            "     |  .. _author's implementation:\n",
            "     |      https://github.com/LiyuanLucasLiu/RAdam\n",
            "     |  .. _Decoupled Weight Decay Regularization:\n",
            "     |      https://arxiv.org/abs/1711.05101\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      RAdam\n",
            "     |      torch.optim.optimizer.Optimizer\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.001, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, weight_decay: float = 0, decoupled_weight_decay: bool = False, *, foreach: Optional[bool] = None, maximize: bool = False, capturable: bool = False, differentiable: bool = False)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  step(self, closure=None)\n",
            "     |      Perform a single optimization step.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable, optional): A closure that reevaluates the model\n",
            "     |              and returns the loss.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "    \n",
            "    class RMSprop(torch.optim.optimizer.Optimizer)\n",
            "     |  RMSprop(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.01, alpha: float = 0.99, eps: float = 1e-08, weight_decay: float = 0, momentum: float = 0, centered=False, capturable=False, foreach: Optional[bool] = None, maximize: bool = False, differentiable: bool = False)\n",
            "     |  \n",
            "     |  Implements RMSprop algorithm.\n",
            "     |  \n",
            "     |  .. math::\n",
            "     |     \\begin{aligned}\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{input}      : \\alpha \\text{ (alpha)},\\: \\gamma \\text{ (lr)},\n",
            "     |              \\: \\theta_0 \\text{ (params)}, \\: f(\\theta) \\text{ (objective)}                   \\\\\n",
            "     |          &\\hspace{13mm}   \\lambda \\text{ (weight decay)},\\: \\mu \\text{ (momentum)},\\: centered\\\\\n",
            "     |          &\\textbf{initialize} : v_0 \\leftarrow 0 \\text{ (square average)}, \\:\n",
            "     |              \\textbf{b}_0 \\leftarrow 0 \\text{ (buffer)}, \\: g^{ave}_0 \\leftarrow 0     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n",
            "     |          &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n",
            "     |          &\\hspace{5mm}if \\: \\lambda \\neq 0                                                    \\\\\n",
            "     |          &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n",
            "     |          &\\hspace{5mm}v_t           \\leftarrow   \\alpha v_{t-1} + (1 - \\alpha) g^2_t\n",
            "     |              \\hspace{8mm}                                                                     \\\\\n",
            "     |          &\\hspace{5mm} \\tilde{v_t} \\leftarrow v_t                                             \\\\\n",
            "     |          &\\hspace{5mm}if \\: centered                                                          \\\\\n",
            "     |          &\\hspace{10mm} g^{ave}_t \\leftarrow g^{ave}_{t-1} \\alpha + (1-\\alpha) g_t            \\\\\n",
            "     |          &\\hspace{10mm} \\tilde{v_t} \\leftarrow \\tilde{v_t} -  \\big(g^{ave}_{t} \\big)^2        \\\\\n",
            "     |          &\\hspace{5mm}if \\: \\mu > 0                                                           \\\\\n",
            "     |          &\\hspace{10mm} \\textbf{b}_t\\leftarrow \\mu \\textbf{b}_{t-1} +\n",
            "     |              g_t/ \\big(\\sqrt{\\tilde{v_t}} +  \\epsilon \\big)                                   \\\\\n",
            "     |          &\\hspace{10mm} \\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\textbf{b}_t                \\\\\n",
            "     |          &\\hspace{5mm} else                                                                   \\\\\n",
            "     |          &\\hspace{10mm}\\theta_t      \\leftarrow   \\theta_{t-1} -\n",
            "     |              \\gamma  g_t/ \\big(\\sqrt{\\tilde{v_t}} + \\epsilon \\big)  \\hspace{3mm}              \\\\\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |          &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |     \\end{aligned}\n",
            "     |  \n",
            "     |  For further details regarding the algorithm we refer to\n",
            "     |  `lecture notes <https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf>`_ by G. Hinton.\n",
            "     |  and centered version `Generating Sequences\n",
            "     |  With Recurrent Neural Networks <https://arxiv.org/pdf/1308.0850v5.pdf>`_.\n",
            "     |  The implementation here takes the square root of the gradient average before\n",
            "     |  adding epsilon (note that TensorFlow interchanges these two operations). The effective\n",
            "     |  learning rate is thus :math:`\\gamma/(\\sqrt{v} + \\epsilon)` where :math:`\\gamma`\n",
            "     |  is the scheduled learning rate and :math:`v` is the weighted moving average\n",
            "     |  of the squared gradient.\n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): iterable of parameters to optimize or dicts defining\n",
            "     |          parameter groups\n",
            "     |      lr (float, Tensor, optional): learning rate (default: 1e-2)\n",
            "     |      momentum (float, optional): momentum factor (default: 0)\n",
            "     |      alpha (float, optional): smoothing constant (default: 0.99)\n",
            "     |      eps (float, optional): term added to the denominator to improve\n",
            "     |          numerical stability (default: 1e-8)\n",
            "     |      centered (bool, optional) : if ``True``, compute the centered RMSProp,\n",
            "     |          the gradient is normalized by an estimation of its variance\n",
            "     |      weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
            "     |      foreach (bool, optional): whether foreach implementation of optimizer\n",
            "     |          is used. If unspecified by the user (so foreach is None), we will try to use\n",
            "     |          foreach over the for-loop implementation on CUDA, since it is usually\n",
            "     |          significantly more performant. Note that the foreach implementation uses\n",
            "     |          ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n",
            "     |          being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n",
            "     |          parameters through the optimizer at a time or switch this flag to False (default: None)\n",
            "     |      maximize (bool, optional): maximize the objective with respect to the\n",
            "     |          params, instead of minimizing (default: False)\n",
            "     |      capturable (bool, optional): whether this instance is safe to\n",
            "     |          capture in a CUDA graph. Passing True can impair ungraphed performance,\n",
            "     |          so if you don't intend to graph capture this instance, leave it False\n",
            "     |          (default: False)\n",
            "     |      differentiable (bool, optional): whether autograd should\n",
            "     |          occur through the optimizer step in training. Otherwise, the step()\n",
            "     |          function runs in a torch.no_grad() context. Setting to True can impair\n",
            "     |          performance, so leave it False if you don't intend to run autograd\n",
            "     |          through this instance (default: False)\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      RMSprop\n",
            "     |      torch.optim.optimizer.Optimizer\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.01, alpha: float = 0.99, eps: float = 1e-08, weight_decay: float = 0, momentum: float = 0, centered=False, capturable=False, foreach: Optional[bool] = None, maximize: bool = False, differentiable: bool = False)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  step(self, closure=None)\n",
            "     |      Perform a single optimization step.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable, optional): A closure that reevaluates the model\n",
            "     |              and returns the loss.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "    \n",
            "    class Rprop(torch.optim.optimizer.Optimizer)\n",
            "     |  Rprop(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.01, etas: Tuple[float, float] = (0.5, 1.2), step_sizes: Tuple[float, float] = (1e-06, 50), *, capturable: bool = False, foreach: Optional[bool] = None, maximize: bool = False, differentiable: bool = False)\n",
            "     |  \n",
            "     |  Implements the resilient backpropagation algorithm.\n",
            "     |  \n",
            "     |  .. math::\n",
            "     |     \\begin{aligned}\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{input}      : \\theta_0 \\in \\mathbf{R}^d \\text{ (params)},f(\\theta)\n",
            "     |              \\text{ (objective)},                                                             \\\\\n",
            "     |          &\\hspace{13mm}      \\eta_{+/-} \\text{ (etaplus, etaminus)}, \\Gamma_{max/min}\n",
            "     |              \\text{ (step sizes)}                                                             \\\\\n",
            "     |          &\\textbf{initialize} :   g^0_{prev} \\leftarrow 0,\n",
            "     |              \\: \\eta_0 \\leftarrow \\text{lr (learning rate)}                                   \\\\\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n",
            "     |          &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n",
            "     |          &\\hspace{5mm} \\textbf{for} \\text{  } i = 0, 1, \\ldots, d-1 \\: \\mathbf{do}            \\\\\n",
            "     |          &\\hspace{10mm}  \\textbf{if} \\:   g^i_{prev} g^i_t  > 0                               \\\\\n",
            "     |          &\\hspace{15mm}  \\eta^i_t \\leftarrow \\mathrm{min}(\\eta^i_{t-1} \\eta_{+},\n",
            "     |              \\Gamma_{max})                                                                    \\\\\n",
            "     |          &\\hspace{10mm}  \\textbf{else if}  \\:  g^i_{prev} g^i_t < 0                           \\\\\n",
            "     |          &\\hspace{15mm}  \\eta^i_t \\leftarrow \\mathrm{max}(\\eta^i_{t-1} \\eta_{-},\n",
            "     |              \\Gamma_{min})                                                                    \\\\\n",
            "     |          &\\hspace{15mm}  g^i_t \\leftarrow 0                                                   \\\\\n",
            "     |          &\\hspace{10mm}  \\textbf{else}  \\:                                                    \\\\\n",
            "     |          &\\hspace{15mm}  \\eta^i_t \\leftarrow \\eta^i_{t-1}                                     \\\\\n",
            "     |          &\\hspace{5mm}\\theta_t \\leftarrow \\theta_{t-1}- \\eta_t \\mathrm{sign}(g_t)             \\\\\n",
            "     |          &\\hspace{5mm}g_{prev} \\leftarrow  g_t                                                \\\\\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |          &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |     \\end{aligned}\n",
            "     |  \n",
            "     |  For further details regarding the algorithm we refer to the paper\n",
            "     |  `A Direct Adaptive Method for Faster Backpropagation Learning: The RPROP Algorithm\n",
            "     |  <http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.1417>`_.\n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): iterable of parameters to optimize or dicts defining\n",
            "     |          parameter groups\n",
            "     |      lr (float, optional): learning rate (default: 1e-2)\n",
            "     |      etas (Tuple[float, float], optional): pair of (etaminus, etaplus), that\n",
            "     |          are multiplicative increase and decrease factors\n",
            "     |          (default: (0.5, 1.2))\n",
            "     |      step_sizes (Tuple[float, float], optional): a pair of minimal and\n",
            "     |          maximal allowed step sizes (default: (1e-6, 50))\n",
            "     |      foreach (bool, optional): whether foreach implementation of optimizer\n",
            "     |          is used. If unspecified by the user (so foreach is None), we will try to use\n",
            "     |          foreach over the for-loop implementation on CUDA, since it is usually\n",
            "     |          significantly more performant. Note that the foreach implementation uses\n",
            "     |          ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n",
            "     |          being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n",
            "     |          parameters through the optimizer at a time or switch this flag to False (default: None)\n",
            "     |      capturable (bool, optional): whether this instance is safe to\n",
            "     |          capture in a CUDA graph. Passing True can impair ungraphed performance,\n",
            "     |          so if you don't intend to graph capture this instance, leave it False\n",
            "     |          (default: False)\n",
            "     |      maximize (bool, optional): maximize the objective with respect to the\n",
            "     |          params, instead of minimizing (default: False)\n",
            "     |      differentiable (bool, optional): whether autograd should\n",
            "     |          occur through the optimizer step in training. Otherwise, the step()\n",
            "     |          function runs in a torch.no_grad() context. Setting to True can impair\n",
            "     |          performance, so leave it False if you don't intend to run autograd\n",
            "     |          through this instance (default: False)\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      Rprop\n",
            "     |      torch.optim.optimizer.Optimizer\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.01, etas: Tuple[float, float] = (0.5, 1.2), step_sizes: Tuple[float, float] = (1e-06, 50), *, capturable: bool = False, foreach: Optional[bool] = None, maximize: bool = False, differentiable: bool = False)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  step(self, closure=None)\n",
            "     |      Perform a single optimization step.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable, optional): A closure that reevaluates the model\n",
            "     |              and returns the loss.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "    \n",
            "    class SGD(torch.optim.optimizer.Optimizer)\n",
            "     |  SGD(params, lr: Union[float, torch.Tensor] = 0.001, momentum: float = 0, dampening: float = 0, weight_decay: float = 0, nesterov=False, *, maximize: bool = False, foreach: Optional[bool] = None, differentiable: bool = False, fused: Optional[bool] = None)\n",
            "     |  \n",
            "     |  Implements stochastic gradient descent (optionally with momentum).\n",
            "     |  \n",
            "     |  .. math::\n",
            "     |     \\begin{aligned}\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{input}      : \\gamma \\text{ (lr)}, \\: \\theta_0 \\text{ (params)}, \\: f(\\theta)\n",
            "     |              \\text{ (objective)}, \\: \\lambda \\text{ (weight decay)},                          \\\\\n",
            "     |          &\\hspace{13mm} \\:\\mu \\text{ (momentum)}, \\:\\tau \\text{ (dampening)},\n",
            "     |          \\:\\textit{ nesterov,}\\:\\textit{ maximize}                                     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                                 \\\\\n",
            "     |          &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n",
            "     |          &\\hspace{5mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{if} \\: \\lambda \\neq 0                                           \\\\\n",
            "     |          &\\hspace{10mm} g_t \\leftarrow g_t + \\lambda  \\theta_{t-1}                            \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{if} \\: \\mu \\neq 0                                               \\\\\n",
            "     |          &\\hspace{10mm}\\textbf{if} \\: t > 1                                                   \\\\\n",
            "     |          &\\hspace{15mm} \\textbf{b}_t \\leftarrow \\mu \\textbf{b}_{t-1} + (1-\\tau) g_t           \\\\\n",
            "     |          &\\hspace{10mm}\\textbf{else}                                                          \\\\\n",
            "     |          &\\hspace{15mm} \\textbf{b}_t \\leftarrow g_t                                           \\\\\n",
            "     |          &\\hspace{10mm}\\textbf{if} \\: \\textit{nesterov}                                       \\\\\n",
            "     |          &\\hspace{15mm} g_t \\leftarrow g_{t} + \\mu \\textbf{b}_t                             \\\\\n",
            "     |          &\\hspace{10mm}\\textbf{else}                                                   \\\\[-1.ex]\n",
            "     |          &\\hspace{15mm} g_t  \\leftarrow  \\textbf{b}_t                                         \\\\\n",
            "     |          &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}                                          \\\\\n",
            "     |          &\\hspace{10mm}\\theta_t \\leftarrow \\theta_{t-1} + \\gamma g_t                   \\\\[-1.ex]\n",
            "     |          &\\hspace{5mm}\\textbf{else}                                                    \\\\[-1.ex]\n",
            "     |          &\\hspace{10mm}\\theta_t \\leftarrow \\theta_{t-1} - \\gamma g_t                   \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |          &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n",
            "     |          &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n",
            "     |     \\end{aligned}\n",
            "     |  \n",
            "     |  Nesterov momentum is based on the formula from\n",
            "     |  `On the importance of initialization and momentum in deep learning`__.\n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): iterable of parameters to optimize or dicts defining\n",
            "     |          parameter groups\n",
            "     |      lr (float, Tensor, optional): learning rate (default: 1e-3)\n",
            "     |      momentum (float, optional): momentum factor (default: 0)\n",
            "     |      weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
            "     |      dampening (float, optional): dampening for momentum (default: 0)\n",
            "     |      nesterov (bool, optional): enables Nesterov momentum (default: False)\n",
            "     |      maximize (bool, optional): maximize the objective with respect to the\n",
            "     |          params, instead of minimizing (default: False)\n",
            "     |      foreach (bool, optional): whether foreach implementation of optimizer\n",
            "     |          is used. If unspecified by the user (so foreach is None), we will try to use\n",
            "     |          foreach over the for-loop implementation on CUDA, since it is usually\n",
            "     |          significantly more performant. Note that the foreach implementation uses\n",
            "     |          ~ sizeof(params) more peak memory than the for-loop version due to the intermediates\n",
            "     |          being a tensorlist vs just one tensor. If memory is prohibitive, batch fewer\n",
            "     |          parameters through the optimizer at a time or switch this flag to False (default: None)\n",
            "     |      differentiable (bool, optional): whether autograd should\n",
            "     |          occur through the optimizer step in training. Otherwise, the step()\n",
            "     |          function runs in a torch.no_grad() context. Setting to True can impair\n",
            "     |          performance, so leave it False if you don't intend to run autograd\n",
            "     |          through this instance (default: False)\n",
            "     |      fused (bool, optional): whether the fused implementation is used.\n",
            "     |          Currently, `torch.float64`, `torch.float32`, `torch.float16`, and `torch.bfloat16`\n",
            "     |          are supported. (default: None)\n",
            "     |  \n",
            "     |  .. note:: The foreach and fused implementations are typically faster than the for-loop,\n",
            "     |            single-tensor implementation, with fused being theoretically fastest with both\n",
            "     |            vertical and horizontal fusion. As such, if the user has not specified either\n",
            "     |            flag (i.e., when foreach = fused = None), we will attempt defaulting to the foreach\n",
            "     |            implementation when the tensors are all on CUDA. Why not fused? Since the fused\n",
            "     |            implementation is relatively new, we want to give it sufficient bake-in time.\n",
            "     |            To specify fused, pass True for fused. To force running the for-loop\n",
            "     |            implementation, pass False for either foreach or fused. \n",
            "     |  \n",
            "     |  \n",
            "     |  Example:\n",
            "     |      >>> # xdoctest: +SKIP\n",
            "     |      >>> optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
            "     |      >>> optimizer.zero_grad()\n",
            "     |      >>> loss_fn(model(input), target).backward()\n",
            "     |      >>> optimizer.step()\n",
            "     |  \n",
            "     |  __ http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf\n",
            "     |  \n",
            "     |  .. note::\n",
            "     |      The implementation of SGD with Momentum/Nesterov subtly differs from\n",
            "     |      Sutskever et al. and implementations in some other frameworks.\n",
            "     |  \n",
            "     |      Considering the specific case of Momentum, the update can be written as\n",
            "     |  \n",
            "     |      .. math::\n",
            "     |          \\begin{aligned}\n",
            "     |              v_{t+1} & = \\mu * v_{t} + g_{t+1}, \\\\\n",
            "     |              p_{t+1} & = p_{t} - \\text{lr} * v_{t+1},\n",
            "     |          \\end{aligned}\n",
            "     |  \n",
            "     |      where :math:`p`, :math:`g`, :math:`v` and :math:`\\mu` denote the\n",
            "     |      parameters, gradient, velocity, and momentum respectively.\n",
            "     |  \n",
            "     |      This is in contrast to Sutskever et al. and\n",
            "     |      other frameworks which employ an update of the form\n",
            "     |  \n",
            "     |      .. math::\n",
            "     |          \\begin{aligned}\n",
            "     |              v_{t+1} & = \\mu * v_{t} + \\text{lr} * g_{t+1}, \\\\\n",
            "     |              p_{t+1} & = p_{t} - v_{t+1}.\n",
            "     |          \\end{aligned}\n",
            "     |  \n",
            "     |      The Nesterov version is analogously modified.\n",
            "     |  \n",
            "     |      Moreover, the initial value of the momentum buffer is set to the\n",
            "     |      gradient value at the first step. This is in contrast to some other\n",
            "     |      frameworks that initialize it to all zeros.\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      SGD\n",
            "     |      torch.optim.optimizer.Optimizer\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, params, lr: Union[float, torch.Tensor] = 0.001, momentum: float = 0, dampening: float = 0, weight_decay: float = 0, nesterov=False, *, maximize: bool = False, foreach: Optional[bool] = None, differentiable: bool = False, fused: Optional[bool] = None)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  __setstate__(self, state)\n",
            "     |  \n",
            "     |  step(self, closure=None)\n",
            "     |      Perform a single optimization step.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable, optional): A closure that reevaluates the model\n",
            "     |              and returns the loss.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "    \n",
            "    class SparseAdam(torch.optim.optimizer.Optimizer)\n",
            "     |  SparseAdam(params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.001, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, maximize: bool = False)\n",
            "     |  \n",
            "     |  SparseAdam implements a masked version of the Adam algorithm\n",
            "     |  suitable for sparse gradients. Currently, due to implementation constraints (explained\n",
            "     |  below), SparseAdam is only intended for a narrow subset of use cases, specifically\n",
            "     |  parameters of a dense layout with gradients of a sparse layout. This occurs in a\n",
            "     |  special case where the module backwards produces grads already in a sparse layout.\n",
            "     |  One example NN module that behaves as such is ``nn.Embedding(sparse=True)``.\n",
            "     |  \n",
            "     |  SparseAdam approximates the Adam algorithm by masking out the parameter and moment\n",
            "     |  updates corresponding to the zero values in the gradients. Whereas the Adam algorithm\n",
            "     |  will update the first moment, the second moment, and the parameters based on all values\n",
            "     |  of the gradients, SparseAdam only updates the moments and parameters corresponding\n",
            "     |  to the non-zero values of the gradients.\n",
            "     |  \n",
            "     |  A simplified way of thinking about the `intended` implementation is as such:\n",
            "     |  \n",
            "     |  1. Create a mask of the non-zero values in the sparse gradients. For example,\n",
            "     |     if your gradient looks like [0, 5, 0, 0, 9], the mask would be [0, 1, 0, 0, 1].\n",
            "     |  2. Apply this mask over the running moments and do computation on only the\n",
            "     |     non-zero values.\n",
            "     |  3. Apply this mask over the parameters and only apply an update on non-zero values.\n",
            "     |  \n",
            "     |  In actuality, we use sparse layout Tensors to optimize this approximation, which means the\n",
            "     |  more gradients that are masked by not being materialized, the more performant the optimization.\n",
            "     |  Since we rely on using sparse layout tensors, we infer that any materialized value in the\n",
            "     |  sparse layout is non-zero and we do NOT actually verify that all values are not zero!\n",
            "     |  It is important to not conflate a semantically sparse tensor (a tensor where many\n",
            "     |  of its values are zeros) with a sparse layout tensor (a tensor where ``.is_sparse``\n",
            "     |  returns ``True``). The SparseAdam approximation is intended for `semantically` sparse\n",
            "     |  tensors and the sparse layout is only a implementation detail. A clearer implementation\n",
            "     |  would be to use MaskedTensors, but those are experimental.\n",
            "     |  \n",
            "     |  \n",
            "     |  .. note::\n",
            "     |  \n",
            "     |      If you suspect your gradients are semantically sparse (but do not have sparse\n",
            "     |      layout), this variant may not be the best for you. Ideally, you want to avoid\n",
            "     |      materializing anything that is suspected to be sparse in the first place, since\n",
            "     |      needing to convert all your grads from dense layout to sparse layout may outweigh\n",
            "     |      the performance gain. Here, using Adam may be the best alternative, unless you\n",
            "     |      can easily rig up your module to output sparse grads similar to\n",
            "     |      ``nn.Embedding(sparse=True)``. If you insist on converting your grads, you can do\n",
            "     |      so by manually overriding your parameters' ``.grad`` fields with their sparse\n",
            "     |      equivalents before calling ``.step()``.\n",
            "     |  \n",
            "     |  \n",
            "     |  Args:\n",
            "     |      params (iterable): iterable of parameters to optimize or dicts defining\n",
            "     |          parameter groups\n",
            "     |      lr (float, Tensor, optional): learning rate (default: 1e-3)\n",
            "     |      betas (Tuple[float, float], optional): coefficients used for computing\n",
            "     |          running averages of gradient and its square (default: (0.9, 0.999))\n",
            "     |      eps (float, optional): term added to the denominator to improve\n",
            "     |          numerical stability (default: 1e-8)\n",
            "     |      maximize (bool, optional): maximize the objective with respect to the\n",
            "     |          params, instead of minimizing (default: False)\n",
            "     |  \n",
            "     |  .. _Adam\\: A Method for Stochastic Optimization:\n",
            "     |      https://arxiv.org/abs/1412.6980\n",
            "     |  \n",
            "     |  Method resolution order:\n",
            "     |      SparseAdam\n",
            "     |      torch.optim.optimizer.Optimizer\n",
            "     |      builtins.object\n",
            "     |  \n",
            "     |  Methods defined here:\n",
            "     |  \n",
            "     |  __init__(self, params: Union[Iterable[torch.Tensor], Iterable[Dict[str, Any]]], lr: Union[float, torch.Tensor] = 0.001, betas: Tuple[float, float] = (0.9, 0.999), eps: float = 1e-08, maximize: bool = False)\n",
            "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
            "     |  \n",
            "     |  step(self, closure=None)\n",
            "     |      Perform a single optimization step.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          closure (Callable, optional): A closure that reevaluates the model\n",
            "     |              and returns the loss.\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes defined here:\n",
            "     |  \n",
            "     |  __annotations__ = {}\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __getstate__(self) -> Dict[str, Any]\n",
            "     |      Helper for pickle.\n",
            "     |  \n",
            "     |  __repr__(self) -> str\n",
            "     |      Return repr(self).\n",
            "     |  \n",
            "     |  __setstate__(self, state: Dict[str, Any]) -> None\n",
            "     |  \n",
            "     |  add_param_group(self, param_group: Dict[str, Any]) -> None\n",
            "     |      Add a param group to the :class:`Optimizer` s `param_groups`.\n",
            "     |      \n",
            "     |      This can be useful when fine tuning a pre-trained network as frozen layers can be made\n",
            "     |      trainable and added to the :class:`Optimizer` as training progresses.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          param_group (dict): Specifies what Tensors should be optimized along with group\n",
            "     |              specific optimization options.\n",
            "     |  \n",
            "     |  load_state_dict(self, state_dict: Dict[str, Any]) -> None\n",
            "     |      Load the optimizer state.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          state_dict (dict): optimizer state. Should be an object returned\n",
            "     |              from a call to :meth:`state_dict`.\n",
            "     |  \n",
            "     |  register_load_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict post-hook which will be called after\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` after calling\n",
            "     |      ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform post-processing after ``load_state_dict`` has loaded the\n",
            "     |      ``state_dict``.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_load_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a load_state_dict pre-hook which will be called before\n",
            "     |      :meth:`~torch.optim.Optimizer.load_state_dict` is called. It should have the\n",
            "     |      following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used and the\n",
            "     |      ``state_dict`` argument is a shallow copy of the ``state_dict`` the user\n",
            "     |      passed in to ``load_state_dict``. The hook may modify the state_dict inplace\n",
            "     |      or optionally return a new one. If a state_dict is returned, it will be used\n",
            "     |      to be loaded into the optimizer.\n",
            "     |      \n",
            "     |      The hook will be called with argument ``self`` and ``state_dict`` before\n",
            "     |      calling ``load_state_dict`` on ``self``. The registered hook can be used to\n",
            "     |      perform pre-processing before the ``load_state_dict`` call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``load_state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_post_hook(self, hook: Callable[[ForwardRef('Optimizer'), Dict[str, Any]], Optional[Dict[str, Any]]], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict post-hook which will be called after :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, state_dict) -> state_dict or None\n",
            "     |      \n",
            "     |      The hook will be called with arguments ``self`` and ``state_dict`` after generating\n",
            "     |      a ``state_dict`` on ``self``. The hook may modify the state_dict inplace or optionally\n",
            "     |      return a new one. The registered hook can be used to perform post-processing\n",
            "     |      on the ``state_dict`` before it is returned.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided post ``hook`` will be fired before\n",
            "     |              all the already registered post-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              post-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_state_dict_pre_hook(self, hook: Callable[[ForwardRef('Optimizer')], NoneType], prepend: bool = False) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register a state dict pre-hook which will be called before :meth:`~torch.optim.Optimizer.state_dict` is called.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      The hook will be called with argument ``self`` before calling ``state_dict`` on ``self``.\n",
            "     |      The registered hook can be used to perform pre-processing before the ``state_dict``\n",
            "     |      call is made.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |          prepend (bool): If True, the provided pre ``hook`` will be fired before\n",
            "     |              all the already registered pre-hooks on ``state_dict``. Otherwise,\n",
            "     |              the provided ``hook`` will be fired after all the already registered\n",
            "     |              pre-hooks. (default: False)\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemoveableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_post_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step post hook which will be called after optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  register_step_pre_hook(self, hook: Callable[[Self, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Tuple[Any, ...], Dict[str, Any]]]]) -> torch.utils.hooks.RemovableHandle\n",
            "     |      Register an optimizer step pre hook which will be called before optimizer step.\n",
            "     |      \n",
            "     |      It should have the following signature::\n",
            "     |      \n",
            "     |          hook(optimizer, args, kwargs) -> None or modified args and kwargs\n",
            "     |      \n",
            "     |      The ``optimizer`` argument is the optimizer instance being used. If\n",
            "     |      args and kwargs are modified by the pre-hook, then the transformed\n",
            "     |      values are returned as a tuple containing the new_args and new_kwargs.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          hook (Callable): The user defined hook to be registered.\n",
            "     |      \n",
            "     |      Returns:\n",
            "     |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            "     |              a handle that can be used to remove the added hook by calling\n",
            "     |              ``handle.remove()``\n",
            "     |  \n",
            "     |  state_dict(self) -> Dict[str, Any]\n",
            "     |      Return the state of the optimizer as a :class:`dict`.\n",
            "     |      \n",
            "     |      It contains two entries:\n",
            "     |      \n",
            "     |      * ``state``: a Dict holding current optimization state. Its content\n",
            "     |          differs between optimizer classes, but some common characteristics\n",
            "     |          hold. For example, state is saved per parameter, and the parameter\n",
            "     |          itself is NOT saved. ``state`` is a Dictionary mapping parameter ids\n",
            "     |          to a Dict with state corresponding to each parameter.\n",
            "     |      * ``param_groups``: a List containing all parameter groups where each\n",
            "     |          parameter group is a Dict. Each parameter group contains metadata\n",
            "     |          specific to the optimizer, such as learning rate and weight decay,\n",
            "     |          as well as a List of parameter IDs of the parameters in the group.\n",
            "     |      \n",
            "     |      NOTE: The parameter IDs may look like indices but they are just IDs\n",
            "     |      associating state with param_group. When loading from a state_dict,\n",
            "     |      the optimizer will zip the param_group ``params`` (int IDs) and the\n",
            "     |      optimizer ``param_groups`` (actual ``nn.Parameter`` s) in order to\n",
            "     |      match state WITHOUT additional verification.\n",
            "     |      \n",
            "     |      A returned state dict might look something like:\n",
            "     |      \n",
            "     |      .. code-block:: text\n",
            "     |      \n",
            "     |          {\n",
            "     |              'state': {\n",
            "     |                  0: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  1: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  2: {'momentum_buffer': tensor(...), ...},\n",
            "     |                  3: {'momentum_buffer': tensor(...), ...}\n",
            "     |              },\n",
            "     |              'param_groups': [\n",
            "     |                  {\n",
            "     |                      'lr': 0.01,\n",
            "     |                      'weight_decay': 0,\n",
            "     |                      ...\n",
            "     |                      'params': [0]\n",
            "     |                  },\n",
            "     |                  {\n",
            "     |                      'lr': 0.001,\n",
            "     |                      'weight_decay': 0.5,\n",
            "     |                      ...\n",
            "     |                      'params': [1, 2, 3]\n",
            "     |                  }\n",
            "     |              ]\n",
            "     |          }\n",
            "     |  \n",
            "     |  zero_grad(self, set_to_none: bool = True) -> None\n",
            "     |      Reset the gradients of all optimized :class:`torch.Tensor` s.\n",
            "     |      \n",
            "     |      Args:\n",
            "     |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            "     |              This will in general have lower memory footprint, and can modestly improve performance.\n",
            "     |              However, it changes certain behaviors. For example:\n",
            "     |              1. When the user tries to access a gradient and perform manual ops on it,\n",
            "     |              a None attribute or a Tensor full of 0s will behave differently.\n",
            "     |              2. If the user requests ``zero_grad(set_to_none=True)`` followed by a backward pass, ``.grad``\\ s\n",
            "     |              are guaranteed to be None for params that did not receive a gradient.\n",
            "     |              3. ``torch.optim`` optimizers have a different behavior if the gradient is 0 or None\n",
            "     |              (in one case it does the step with a gradient of 0 and in the other it skips\n",
            "     |              the step altogether).\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Static methods inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  profile_hook_step(func: Callable[~_P, ~R]) -> Callable[~_P, ~R]\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data descriptors inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  __dict__\n",
            "     |      dictionary for instance variables\n",
            "     |  \n",
            "     |  __weakref__\n",
            "     |      list of weak references to the object\n",
            "     |  \n",
            "     |  ----------------------------------------------------------------------\n",
            "     |  Data and other attributes inherited from torch.optim.optimizer.Optimizer:\n",
            "     |  \n",
            "     |  OptimizerPostHook = typing.Callable[[typing.Self, typing.Tuple[typin.....\n",
            "     |  \n",
            "     |  OptimizerPreHook = typing.Callable[[typing.Self, typing.Tuple[typin......\n",
            "\n",
            "DATA\n",
            "    __all__ = ['Adafactor', 'Adadelta', 'Adagrad', 'Adam', 'Adamax', 'Adam...\n",
            "\n",
            "FILE\n",
            "    /usr/local/lib/python3.11/dist-packages/torch/optim/__init__.py\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(2):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2iFVY4p0zm1p",
        "outputId": "61577646-2ecf-4049-d486-6bd6265a7213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,  2000] loss: 1.854\n",
            "[1,  4000] loss: 1.499\n",
            "[1,  6000] loss: 1.341\n",
            "[1,  8000] loss: 1.208\n",
            "[1, 10000] loss: 1.128\n",
            "[1, 12000] loss: 1.105\n",
            "[2,  2000] loss: 0.989\n",
            "[2,  4000] loss: 0.977\n",
            "[2,  6000] loss: 0.959\n",
            "[2,  8000] loss: 0.950\n",
            "[2, 10000] loss: 0.926\n",
            "[2, 12000] loss: 0.937\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './cifar_net.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "wYSCaiav0l-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Q0Ctu3Vi0pxh",
        "outputId": "fa139d49-ee39-47c2-dc99-1e7d1b6d6a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GroundTruth:  cat   ship  ship  plane\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = Net()\n",
        "net.load_state_dict(torch.load(PATH, weights_only=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "I_uZtCQC0wUo",
        "outputId": "1be7ab0d-0ddf-4675-f366-8e70ae69924f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Net' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-8026802ab3ed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Net' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = net(images)"
      ],
      "metadata": {
        "id": "ycg0B14V0xHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
        "                              for j in range(4)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akjAbcBW00HR",
        "outputId": "83c9cedd-4018-47b0-93ff-90809f95a3b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted:  cat   ship  plane ship \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "# since we're not training, we don't need to calculate the gradients for our outputs\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = net(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZBF7Udd05Bt",
        "outputId": "000793df-1f52-45f0-bdca-ee8e926159d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 67 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare to count predictions for each class\n",
        "correct_pred = {classname: 0 for classname in classes}\n",
        "total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "# again no gradients needed\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = net(images)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        # collect the correct predictions for each class\n",
        "        for label, prediction in zip(labels, predictions):\n",
        "            if label == prediction:\n",
        "                correct_pred[classes[label]] += 1\n",
        "            total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "# print accuracy for each class\n",
        "for classname, correct_count in correct_pred.items():\n",
        "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGlGBbxp2xQo",
        "outputId": "1a1544cb-16b4-4dc1-cc9c-b020cc03714b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class: plane is 68.9 %\n",
            "Accuracy for class: car   is 76.6 %\n",
            "Accuracy for class: bird  is 66.2 %\n",
            "Accuracy for class: cat   is 41.9 %\n",
            "Accuracy for class: deer  is 46.3 %\n",
            "Accuracy for class: dog   is 59.7 %\n",
            "Accuracy for class: frog  is 69.6 %\n",
            "Accuracy for class: horse is 75.0 %\n",
            "Accuracy for class: ship  is 89.1 %\n",
            "Accuracy for class: truck is 79.5 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "id": "ljhbbRRI3DpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.to(device)"
      ],
      "metadata": {
        "id": "mIQBXLEF3G8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs, labels = data[0].to(device), data[1].to(device)"
      ],
      "metadata": {
        "id": "W56RSbqP3I2C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}